{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pickle\n",
    "import ast\n",
    "import math\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from given CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3452</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Loving these vintage springs on my vintage str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1205</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Works great as a guitar bench mat. Not rugged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1708</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>We use these for everything from our acoustic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2078</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Great price and good quality.  It didn't quite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>I bought this bass to split time as my primary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>it's more on toy side than on instrument side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1329</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Absolute BEST guitar hangers on the market... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>325</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Great nylon strings, just as expected. They wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>I bought this stand for church because I been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1714</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>Awesome stand!\\n\\nTip: The bottom part that su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Image  \\\n",
       "0        3452  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "1        1205  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "2        1708  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "3        2078  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "4         801  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "5         126  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "6        1329  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "7         325  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "8         245  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "9        1714  ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "\n",
       "                                         Review Text  \n",
       "0  Loving these vintage springs on my vintage str...  \n",
       "1  Works great as a guitar bench mat. Not rugged ...  \n",
       "2  We use these for everything from our acoustic ...  \n",
       "3  Great price and good quality.  It didn't quite...  \n",
       "4  I bought this bass to split time as my primary...  \n",
       "5  it's more on toy side than on instrument side,...  \n",
       "6  Absolute BEST guitar hangers on the market... ...  \n",
       "7  Great nylon strings, just as expected. They wo...  \n",
       "8  I bought this stand for church because I been ...  \n",
       "9  Awesome stand!\\n\\nTip: The bottom part that su...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'A2_Data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all image links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for idx, row in data.iterrows():\n",
    "    link_arr = ast.literal_eval(row[1])\n",
    "    for link in link_arr:\n",
    "        links.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining transformations for pre-processing on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model to be used for feature extraction of images. In this case I have used ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aditya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download any image given it's link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(link):\n",
    "    response = requests.get(link)\n",
    "    try:\n",
    "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get image from {link} due to error {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/71F3npeHUDL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65675A30>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/71wHUWncMGL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65675A30>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/71B8OOE5N8L._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65AAE250>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/81SX3oAWbNL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65AAF9C0>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/718niQ1GEwL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65CE1FD0>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/61OboZT-kcL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65D08E50>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/710a2Pyh5lL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65D99CB0>\n",
      "Failed to get image from https://images-na.ssl-images-amazon.com/images/I/816NMd0LexL._SY88.jpg due to error cannot identify image file <_io.BytesIO object at 0x000002BF65D9B920>\n"
     ]
    }
   ],
   "source": [
    "images = {}\n",
    "for link in links:\n",
    "    image = download_images(link)\n",
    "    if images is None:\n",
    "        continue\n",
    "    else:\n",
    "        images[link] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to transform image and extract it's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_extract_features(img):\n",
    "    # Apply the preprocessing transformations\n",
    "    img_t = transform(img)\n",
    "    img_t = img_t.unsqueeze(0)  \n",
    "    img_t = img_t.to(device)  \n",
    "    \n",
    "    # Extract features with no gradient calculation for efficiency\n",
    "    with torch.no_grad():\n",
    "        features = model(img_t)\n",
    "\n",
    "    features_flattened = features.view(-1)\n",
    "    # Move the features to CPU for further processing or storage\n",
    "    features_flattened = features_flattened.cpu()\n",
    "    \n",
    "    return features_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_features = {}\n",
    "for link, img in images.items():\n",
    "    if img is None:\n",
    "        continue\n",
    "    images_features[link] = preprocess_and_extract_features(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading the image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = 'image_features.pkl'\n",
    "\n",
    "with open(features_path, 'wb') as file:\n",
    "    pickle.dump(images_features, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = 'image_features.pkl'\n",
    "\n",
    "with open(features_path, 'rb') as file:\n",
    "    image_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all textual data from the reviews column into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for idx, row in data.iterrows():\n",
    "    if pd.isna(row[2]):\n",
    "        reviews.append(\"\")\n",
    "        continue\n",
    "    text = row[2]\n",
    "    reviews.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying necessary text pre-processing on the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercasing the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing all punctuations\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenizing text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization on tokens \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing all documents\n",
    "tokenized_docs = []\n",
    "for doc in reviews:\n",
    "    tokenized_docs.append(preprocess_text(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for calculating term frequency and inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_per_document(document):\n",
    "    tf_dict = {}\n",
    "    doc_len = len(document)\n",
    "    for term in document:\n",
    "        tf_dict[term] = tf_dict.get(term, 0) + 1 / float(doc_len)\n",
    "    return tf_dict\n",
    "\n",
    "def compute_tf_all_documents(tokenized_docs):\n",
    "    return [compute_tf_per_document(doc) for doc in tokenized_docs]\n",
    "\n",
    "def compute_idf(documents):\n",
    "    idf_dict = {}\n",
    "    N = len(documents)\n",
    "    \n",
    "    # Initialize document frequency (DF) counts\n",
    "    for document in documents:\n",
    "        for word in document:\n",
    "            if word in idf_dict:\n",
    "                idf_dict[word] += 1\n",
    "            else:\n",
    "                idf_dict[word] = 1\n",
    "    \n",
    "    # Convert DF counts to IDF scores\n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = {}\n",
    "    for word, val in tf.items():\n",
    "        tf_idf[word] = val * idf[word]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing tf-idf scores for all terms across the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_scores_per_document = [compute_tf_per_document(doc) for doc in tokenized_docs]\n",
    "\n",
    "idf_dict = compute_idf(tokenized_docs)\n",
    "\n",
    "tf_idf_scores_per_document = [compute_tf_idf(tf, idf_dict) for tf in tf_scores_per_document]\n",
    "\n",
    "global_tf_idf_scores = {}\n",
    "for doc_scores in tf_idf_scores_per_document:\n",
    "    for term, score in doc_scores.items():\n",
    "        if term in global_tf_idf_scores:\n",
    "            global_tf_idf_scores[term] += score\n",
    "        else:\n",
    "            global_tf_idf_scores[term] = score\n",
    "\n",
    "for term in global_tf_idf_scores.keys():\n",
    "    global_tf_idf_scores[term] /= len(tf_idf_scores_per_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading the tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = 'tf_idf_scores.pkl'\n",
    "\n",
    "with open(text_features, 'wb') as file:\n",
    "    pickle.dump(global_tf_idf_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = 'tf_idf_scores.pkl'\n",
    "\n",
    "with open(text_features, 'rb') as file:\n",
    "    text_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a *Query* class to handle all input queries of the form (ImageLink, Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, link, review):\n",
    "        self.img_link = link\n",
    "        self.text_review = review\n",
    "\n",
    "    def get_query_link(self):\n",
    "        return self.img_link\n",
    "    \n",
    "    def get_query_review(self):\n",
    "        return self.text_review\n",
    "\n",
    "    def process_image_features(self):\n",
    "        # This function downloads the image and extracts features\n",
    "        img_features = preprocess_and_extract_features(download_images(self.img_link))\n",
    "        return img_features\n",
    "\n",
    "    def most_similar_images(self, tensor_dict):\n",
    "        # Returns the most similar images on the basis of cosine similarity score calculated using torch library\n",
    "        input_tensor = self.process_image_features()\n",
    "        similarities = {}\n",
    "        for link, tensor in tensor_dict.items():\n",
    "            similarity = torch.nn.functional.cosine_similarity(input_tensor.unsqueeze(0), tensor.unsqueeze(0))\n",
    "            similarities[link] = similarity.item()\n",
    "        sorted_tensors = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_tensors\n",
    "\n",
    "    def process_text_features(self):\n",
    "        # This function preprocesses the query text\n",
    "        return sorted(preprocess_text(self.text_review))\n",
    "\n",
    "    # This function compiles all previously defined functions to process the query give the respective output\n",
    "    def process_query(self, image_tensor_dict, text_reviews, global_tf_idf_scores):\n",
    "        # Using image retrieval\n",
    "        image_similarities = self.most_similar_images(image_tensor_dict)\n",
    "        \n",
    "        print(\"USING IMAGE RETRIEVAL\")\n",
    "        image_cosine_scores = []\n",
    "        for i, (img_url, img_similarity) in enumerate(image_similarities[1:4]):\n",
    "            print(f\"{i+1}) Image URL: {img_url}\")            \n",
    "            image_cosine_score = img_similarity \n",
    "            print(f\"Cosine similarity of images: {image_cosine_score}\")\n",
    "            \n",
    "            image_cosine_scores.append(image_cosine_score)\n",
    "        \n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "        # Calculate average cosine similarity scores for image retrieval\n",
    "        if image_cosine_scores:\n",
    "            avg_image_cosine_score = sum(image_cosine_scores) / len(image_cosine_scores)\n",
    "            print(f\"Average cosine similarity of images: {avg_image_cosine_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING IMAGE RETRIEVAL\n",
      "1) Image URL: https://images-na.ssl-images-amazon.com/images/I/71eH74UgOwL._SY88.jpg\n",
      "Cosine similarity of images: 0.865452229976654\n",
      "2) Image URL: https://images-na.ssl-images-amazon.com/images/I/61g0lol4mUL._SY88.jpg\n",
      "Cosine similarity of images: 0.8546483516693115\n",
      "3) Image URL: https://images-na.ssl-images-amazon.com/images/I/711kGbkdzEL._SY88.jpg\n",
      "Cosine similarity of images: 0.8517411947250366\n",
      "------------------------------------------\n",
      "Average cosine similarity of images: 0.8572805921236674\n"
     ]
    }
   ],
   "source": [
    "# Sample usage of Query class\n",
    "query = Query(\"https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg\",\n",
    "              \"I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\")\n",
    "\n",
    "query.process_query(image_features, reviews, global_tf_idf_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
